# backend/sinais.py ‚Äî atualizado para carregar modelos por ativo (CSV-trained)
import MetaTrader5 as mt5
import pandas as pd
import numpy as np
import psycopg2
import feedparser
import logging
import os
from datetime import datetime
from sklearn.linear_model import SGDClassifier
import filelock
import time
import json
from pathlib import Path
import joblib
# === CONFIG / PATHS (Copied from backtest_ia_5min.py) ===
log_dir = 'C:\\temp'
os.makedirs(log_dir, exist_ok=True)
LOCK_PATH = os.path.join(log_dir, "sinal_lock.txt")
SINAIS_CSV = os.path.join(log_dir, "sinais_ao_vivo.csv")

# --- Copied from backtest_ia_5min.py ---
OUT_PATH = r"C:\Users\Marco\ia_finance"
MODELS_DIR = os.path.join(OUT_PATH, "modelos")
os.makedirs(MODELS_DIR, exist_ok=True)

# Path to the pipeline_results.json generated by backtest_ia_5min.py
PIPELINE_RESULTS_PATH = os.path.join(OUT_PATH, "pipeline_results.json")

# Path to the Hall of Fame strategies
HALL_OF_FAME_PATH_TEMPLATE = os.path.join(OUT_PATH, "{}_hall_of_fame.json")

ASSET_CONFIG = {
    "PETR4": {"point_value": 1,    "commission": 0.02, "slippage_points": 0.02},
    "WIN":   {"point_value": 0.2,  "commission": 1.00, "slippage_points": 10},
    "WDO":   {"point_value": 10,   "commission": 3.00, "slippage_points": 1},
}

# --- FIX: Map live symbols to the generic symbols used in backtesting ---
SYMBOL_MAP = {
    "WINZ25": "WIN",
    "WDOZ25": "WDO",
    # Add other future contracts here as they change, e.g., "WING26": "WIN"
}

# --- Global cache for loaded models, features, and ensemble configs ---
loaded_ml_models = {}
loaded_ml_features = {}
loaded_hall_of_fame = {}
loaded_ensemble_configs = {} # To store best_sl_atr, best_tp_atr, and optimized_ml_threshold

# === LOG ===
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('IA_MT5')
handler = logging.FileHandler(os.path.join(log_dir, 'ia_mt5.log'), encoding='utf-8')
handler.setFormatter(logging.Formatter('%(asctime)s | %(levelname)s | %(message)s'))

# Ensure only one handler is added to avoid duplicate log entries if script is reloaded
if not logger.handlers or not any(isinstance(h, logging.FileHandler) and h.baseFilename == handler.baseFilename for h in logger.handlers):
    # Remove existing FileHandlers if they point to the same file
    logger.handlers = [h for h in logger.handlers if not (isinstance(h, logging.FileHandler) and h.baseFilename == handler.baseFilename)]
    logger.addHandler(handler)

# === GLOBALS ===
ultimo_sinal = None
cache_local = {}
ultima_verificacao_noticias = None
cache_noticias = 0.0
historico_dados = {}
# modelo default para incremental (mantive, mas n√£o mais usado para treino cont√≠nuo)

# ----------------------
# LOCK helpers
# ----------------------
def sinal_bloqueado():
    return os.path.exists(LOCK_PATH)

def bloquear_sinal():
    try:
        with open(LOCK_PATH, "w") as f:
            f.write(str(time.time()))
        logger.info("üîí Lock criado: sinal bloqueado")
        return True
    except Exception as e:
        logger.error(f"Erro criar lock: {e}")
        return False

def liberar_sinal():
    try:
        if os.path.exists(LOCK_PATH):
            os.remove(LOCK_PATH)
            logger.info("üîì Lock removido: sinais liberados")
    except Exception as e:
        logger.error(f"Erro remover lock: {e}")

# ----------------------
# MODEL IO
# ----------------------
def model_path_for(symbol):
    return os.path.join(MODELS_DIR, f"{symbol}_lgbm_model.joblib")

def features_path_for(symbol):
    return os.path.join(MODELS_DIR, f"{symbol}_features.json")

def load_ensemble_config_from_pipeline_results(symbol):
    """Loads ensemble SL/TP and ML threshold from pipeline_results.json."""
    # Use the mapped base symbol to find the correct results
    base_symbol = SYMBOL_MAP.get(symbol, symbol)

    if base_symbol in loaded_ensemble_configs:
        return loaded_ensemble_configs[base_symbol]

    if not os.path.exists(PIPELINE_RESULTS_PATH):
        logger.warning(f"Arquivo de resultados do pipeline n√£o encontrado: {PIPELINE_RESULTS_PATH}")
        return None
    try:
        with open(PIPELINE_RESULTS_PATH, 'r', encoding='utf-8') as f:
            results = json.load(f)

        symbol_results = results.get(base_symbol)
        if not symbol_results:
            logger.warning(f"Resultados para {base_symbol} (mapeado de {symbol}) n√£o encontrados em {PIPELINE_RESULTS_PATH}")
            return None
        
        ensemble_metrics = symbol_results.get('ensemble_metrics', {})
        ml_filtered_metrics = symbol_results.get('final_ml_filtered_metrics', {})

        config = {
            'best_sl_atr': ensemble_metrics.get('best_sl_atr', 2.0),
            'best_tp_atr': ensemble_metrics.get('best_tp_atr', 4.0),
            'optimized_ml_threshold': ml_filtered_metrics.get('optimized_ml_threshold', 0.55) # Assuming we add this to backtest_ia_5min.py output
        }
        loaded_ensemble_configs[base_symbol] = config
        logger.info(f"Configura√ß√µes de ensemble para {base_symbol} carregadas: {config}")
        return config
    except Exception as e:
        logger.error(f"Erro ao carregar configura√ß√µes de ensemble para {base_symbol}: {e}")
        return None

def load_hall_of_fame_strategies(symbol):
    """Loads Hall of Fame strategies for a given symbol."""
    # Use the mapped base symbol to find the correct Hall of Fame file
    base_symbol = SYMBOL_MAP.get(symbol, symbol)

    if base_symbol in loaded_hall_of_fame:
        return loaded_hall_of_fame[base_symbol]

    hall_of_fame_file = HALL_OF_FAME_PATH_TEMPLATE.format(base_symbol)
    if not os.path.exists(hall_of_fame_file):
        logger.warning(f"Hall of Fame n√£o encontrado para {base_symbol} (mapeado de {symbol}): {hall_of_fame_file}")
        return []
    try:
        with open(hall_of_fame_file, 'r') as f:
            loaded_pop = json.load(f)
        
        # Apply compatibility fixes as in backtest_ia_5min.py
        seed_pop = []
        for ind in loaded_pop:
            ind.setdefault('direction', 1) # Default to long if not present
            ind.setdefault('sl_atr', 2.0)
            ind.setdefault('tp_atr', 4.0)
            seed_pop.append(ind)
        loaded_hall_of_fame[base_symbol] = seed_pop
        logger.info(f"Hall of Fame para {base_symbol} carregado: {len(seed_pop)} estrat√©gias.")
        return seed_pop
    except Exception as e:
        logger.error(f"Erro ao carregar Hall of Fame para {base_symbol}: {e}")
        return []

def carregar_modelo_IA(symbol):
    # Use the mapped base symbol to find the correct model
    base_symbol = SYMBOL_MAP.get(symbol, symbol)

    if base_symbol in loaded_ml_models:
        return loaded_ml_models[base_symbol]
    try:
        p = model_path_for(base_symbol)
        if not os.path.exists(p):
            logger.info(f"Modelo n√£o encontrado para {base_symbol} (mapeado de {symbol}): {p}")
            return None
        model = joblib.load(p)
        logger.info(f"Modelo carregado: {p}")
        loaded_ml_models[base_symbol] = model
        return model
    except Exception as e:
        logger.error(f"Erro carregar_modelo_IA({base_symbol}): {e}")
        return None    

def carregar_features_IA(symbol):
    # Use the mapped base symbol to find the correct features file
    base_symbol = SYMBOL_MAP.get(symbol, symbol)

    if base_symbol in loaded_ml_features:
        return loaded_ml_features[base_symbol]
    try:
        p = features_path_for(base_symbol)
        # --- FIX: Use os.path.exists() for string paths ---
        if not os.path.exists(p):
            logger.info(f"Arquivo de features n√£o encontrado para {base_symbol} (mapeado de {symbol}): {p}")
            return None
        with open(p, 'r') as f:
            features_data = json.load(f)
        features = features_data.get('features')
        if not features:
            logger.error(f"Nenhuma feature encontrada no arquivo {p}")
            return None
        loaded_ml_features[base_symbol] = features
        logger.info(f"Features para {base_symbol} carregadas: {len(features)} features.")
        return features
    except Exception as e:
        logger.error(f"Erro ao carregar features para {base_symbol}: {e}")
        return None

# ----------------------
# MT5 helpers (Copied from backtest_ia_5min.py)
# ----------------------
def initialize_mt5(retries: int = 3, delay: float = 1.0):
    for tentativa in range(retries):
        try:
            ok = mt5.initialize()
        except Exception as e:
            logger.warning(f"mt5.initialize() exce√ß√£o: {e}")
            ok = False
        if ok:
            logger.info("‚úÖ MT5 inicializado")
            return True
        time.sleep(delay)
    logger.error("‚ùå Falha ao inicializar MT5")
    return False

def selecionar_simbolo(simbolo: str):
    try:
        ok = mt5.symbol_select(simbolo, True)
        if ok:
            logger.debug(f"S√≠mbolo selecionado: {simbolo}")
            return True
        else:
            logger.warning(f"symbol_select falhou: {simbolo}")
            return False
    except Exception as e:
        logger.error(f"selecionar_simbolo erro: {e}")
        return False

def executar_ordem(symbol, sinal, preco, sl, tp, volume, tp_id):
    """Envio seguro de ordem (ajusta price, volume, digits, filling, deviation)."""
    try:
        if not mt5.symbol_select(symbol, True):
            logger.error(f"executar_ordem: n√£o selecionou {symbol}")
            return False

        info = mt5.symbol_info(symbol)
        if info is None:
            logger.error(f"executar_ordem: info None para {symbol}")
            return False

        # volume ajustado
        try:
            vol_min = float(info.volume_min) if info.volume_min else 0.0
            vol_step = float(info.volume_step) if info.volume_step else 0.0
        except Exception:
            vol_min = 0.0; vol_step = 0.0

        if vol_min > 0 and volume < vol_min:
            volume = vol_min
        if vol_step > 0:
            n = round(volume / vol_step)
            volume = max(vol_min, n * vol_step)

        # price (ask for buy, bid for sell)
        if sinal.upper() == "COMPRA":
            price = float(info.ask) if hasattr(info, "ask") else float(preco)
            order_type = mt5.ORDER_TYPE_BUY
        else:
            price = float(info.bid) if hasattr(info, "bid") else float(preco)
            order_type = mt5.ORDER_TYPE_SELL

        digits = int(info.digits) if hasattr(info,'digits') and info.digits is not None else None
        if digits is not None:
            price = round(price, digits)
            sl = round(float(sl), digits)
            tp = round(float(tp), digits)

        request = {
            "action": mt5.TRADE_ACTION_DEAL,
            "symbol": symbol,
            "type": order_type,
            "volume": float(volume),
            "price": float(price),
            "sl": float(sl),
            "tp": float(tp),
            "magic": 20250125 + int(tp_id),
            "deviation": 20,
            "type_time": mt5.ORDER_TIME_GTC,
            "type_filling": getattr(mt5, "ORDER_FILLING_FOK", getattr(mt5, "ORDER_FILLING_IOC", mt5.ORDER_FILLING_IOC)),
            "comment": f"IA_TP{tp_id}"
        }

        result = mt5.order_send(request)
        if result is None:
            logger.error(f"executar_ordem: MT5 retornou None para {symbol}")
            return False

        logger.info(f"executar_ordem result: symbol={symbol} retcode={getattr(result,'retcode',None)} comment={getattr(result,'comment','')}")
        if hasattr(mt5, "TRADE_RETCODE_DONE") and getattr(result, "retcode", None) == mt5.TRADE_RETCODE_DONE:
            return True

        logger.warning(f"executar_ordem rejeitada: retcode={getattr(result,'retcode',None)} comment={getattr(result,'comment','')}")
        return False
    except Exception as e:
        logger.error(f"executar_ordem exce√ß√£o: {e}")
        return False

def is_petr4_market_hours(index):
    return (index.hour >= 10) & (index.minute >= 30) & (index.hour < 17)

def is_wdo_market_hours(index):
    return ((index.hour >= 9) & (index.minute >= 5) & (index.hour < 12)) | \
           ((index.hour >= 14) & (index.hour < 17))

def ensure_ema_exists(df, span):
    col = f'ema_{span}'
    if col not in df.columns:
        df[col] = df['close'].ewm(span=span, adjust=False).mean()

def add_features(df):
    df = df.copy()
    c = df['close']

    spans = [5,8,9,13,21,34,50,89,100,200]
    for span in spans:
        df[f'ema_{span}'] = c.ewm(span=span, adjust=False).mean()
        df[f'sma_{span}'] = c.rolling(span).mean()

    delta = c.diff()
    up = delta.clip(lower=0); down = -delta.clip(upper=0)
    rsi = 100 - 100/(1 + (up.rolling(14).mean() / (down.rolling(14).mean().replace(0, np.nan))))
    df['rsi_14'] = rsi

    tr = pd.concat([
        (df['high'] - df['low']).abs(),
        (df['high'] - c.shift(1)).abs(),
        (df['low'] - c.shift(1)).abs()
    ], axis=1).max(axis=1)
    df['atr_14'] = tr.rolling(14).mean()

    df['vol'] = (df['high'] - df['low']) / df['close'].shift(1)
    df['vol_med'] = df['vol'].rolling(50).mean()

    volume_col = 'vol' if 'vol' in df.columns else 'tickvol'
    if volume_col in df.columns:
        df['price_vol'] = (df['close'] * df[volume_col])
        df['cum_vol'] = df.groupby(df.index.date)[volume_col].cumsum()
        df['cum_price_vol'] = df.groupby(df.index.date)['price_vol'].cumsum()
        df['vwap'] = df['cum_price_vol'] / df['cum_vol']
        df.drop(columns=['price_vol', 'cum_vol', 'cum_price_vol'], inplace=True)
    else:
        logger.warning("VWAP not calculated: 'vol' or 'tickvol' column not found.")

    df['rolling_std_20'] = c.rolling(20).std()
    df['rolling_high_20'] = df['high'].rolling(20).max()
    df['rolling_low_20'] = df['low'].rolling(20).min()
    df['candle_range'] = df['high'] - df['low']

    sma_20 = df['close'].rolling(20).mean()
    std_20 = df['close'].rolling(20).std()
    df['bb_upper'] = sma_20 + (std_20 * 2)
    df['bb_lower'] = sma_20 - (std_20 * 2)
    df['bb_mid'] = sma_20

    df = df.dropna()
    return df

def signal_from_strategy(df, ind):
    fam = ind['family']; p = ind['params']
    if fam == 'macross':
        for s in [p.get('fast'), p.get('slow')]:
            if s is not None:
                ensure_ema_exists(df, s)

    is_petr4 = 'PETR4' in df.attrs.get('asset_name', '')
    time_filter = is_petr4_market_hours(df.index) if is_petr4 else True

    direction = ind.get('direction', 1)
    buy_signal = pd.Series(False, index=df.index)
    sell_signal = pd.Series(False, index=df.index)

    if fam == 'pullback':
        for s in [21,50,200]:
            ensure_ema_exists(df, s)
        
        if direction in [1, 0]:
            buy_signal = (df['close'] < df['ema_21']) & (df['close'].shift(1) >= df['ema_21'].shift(1))
            buy_signal &= (df['vol'] > df['vol_med'] * p['vol_mult'])
            buy_signal &= (df['close'] > df['ema_50']) & (df['ema_50'] > df['ema_200'])
        if direction in [-1, 0]:
            sell_signal = (df['close'] > df['ema_21']) & (df['close'].shift(1) <= df['ema_21'].shift(1))
            sell_signal &= (df['vol'] > df['vol_med'] * p['vol_mult'])
            sell_signal &= (df['close'] < df['ema_50']) & (df['ema_50'] < df['ema_200'])
        
        signal = pd.Series(np.where(buy_signal, 1, np.where(sell_signal, -1, 0)), index=df.index)
        signal &= time_filter
        return signal

    elif fam == 'macross':
        fast = p['fast']; slow = p['slow']
        if direction in [1, 0]:
            buy_signal = (df[f'ema_{fast}'] > df[f'ema_{slow}']) & (df[f'ema_{fast}'].shift(1) <= df[f'ema_{slow}'].shift(1))
        if direction in [-1, 0]:
            sell_signal = (df[f'ema_{fast}'] < df[f'ema_{slow}']) & (df[f'ema_{fast}'].shift(1) >= df[f'ema_{slow}'].shift(1))
        
        signal = pd.Series(np.where(buy_signal, 1, np.where(sell_signal, -1, 0)), index=df.index)
        signal &= time_filter
        return signal

    elif fam == 'volbreak':
        lookback = p['lookback']; mult = p['mult']
        rolling_std = df['close'].pct_change().rolling(lookback).std()
        threshold = rolling_std * mult
        candle_move = (df['close'] - df['open']).abs() / df['open'].shift(1)
        is_break = (candle_move > threshold) & (df['vol'] > df['vol_med']*0.8)
        
        if direction in [1, 0]:
            buy_signal = is_break & (df['close'] > df['open'])
        if direction in [-1, 0]:
            sell_signal = is_break & (df['close'] < df['open'])

        signal = pd.Series(np.where(buy_signal, 1, np.where(sell_signal, -1, 0)), index=df.index)
        signal &= time_filter
        return signal

    elif fam == 'reversal':
        rsi_level = p['rsi_level']
        if direction in [1, 0]:
            buy_signal = (df['rsi_14'] < rsi_level) & (df['rsi_14'].shift(1) >= rsi_level)
        if direction in [-1, 0]:
            sell_signal = (df['rsi_14'] > (100 - rsi_level)) & (df['rsi_14'].shift(1) <= (100 - rsi_level))
        
        signal = pd.Series(np.where(buy_signal, 1, np.where(sell_signal, -1, 0)), index=df.index)
        signal &= time_filter
        return signal

    elif fam == 'vwap_bounce':
        if direction in [1, 0]:
            buy_signal = (df['close'] > df['vwap']) & (df['close'].shift(1) <= df['vwap'].shift(1))
        if direction in [-1, 0]:
            sell_signal = (df['close'] < df['vwap']) & (df['close'].shift(1) >= df['vwap'].shift(1))
        
        signal = pd.Series(np.where(buy_signal, 1, np.where(sell_signal, -1, 0)), index=df.index)
        signal &= time_filter
        return signal

    elif fam == 'vwap_std_reversion':
        if 'vwap' not in df.columns: return pd.Series(0, index=df.index)
        std_mult = p['std_mult']
        
        if direction in [1, 0]:
            buy_signal = df['close'] < (df['vwap'] - std_mult * df['rolling_std_20'])
        if direction in [-1, 0]:
            sell_signal = df['close'] > (df['vwap'] + std_mult * df['rolling_std_20'])
        
        signal = pd.Series(np.where(buy_signal, 1, np.where(sell_signal, -1, 0)), index=df.index)
        signal &= is_wdo_market_hours(df.index)
        return signal

    elif fam == 'vwap_rejection':
        if 'vwap' not in df.columns: return pd.Series(0, index=df.index)
        is_neg_candle = df['close'] < df['open']
        is_pos_candle = df['close'] > df['open']
        
        if direction in [1, 0]:
            buy_signal = (df['close'] < df['vwap']) & is_pos_candle
        if direction in [-1, 0]:
            sell_signal = (df['close'] > df['vwap']) & is_neg_candle
        
        signal = pd.Series(np.where(buy_signal, 1, np.where(sell_signal, -1, 0)), index=df.index)
        signal &= is_wdo_market_hours(df.index)
        return signal

    elif fam == 'atr_breakout':
        atr_mult = p['atr_mult']
        if direction in [1, 0]:
            buy_signal = df['close'] > (df['rolling_high_20'] + atr_mult * df['atr_14'])
        if direction in [-1, 0]:
            sell_signal = df['close'] < (df['rolling_low_20'] - atr_mult * df['atr_14'])
        
        signal = pd.Series(np.where(buy_signal, 1, np.where(sell_signal, -1, 0)), index=df.index)
        signal &= is_wdo_market_hours(df.index)
        return signal

    elif fam == 'candle_reversal':
        body_pct = p['body_pct']
        
        if direction in [1, 0]:
            buy_signal = (df['low'] < df['low'].shift(1)) & (df['close'] > (df['high'] - df['candle_range'] * body_pct))
        if direction in [-1, 0]:
            sell_signal = (df['high'] > df['high'].shift(1)) & (df['close'] < (df['low'] + df['candle_range'] * body_pct))
        
        signal = pd.Series(np.where(buy_signal, 1, np.where(sell_signal, -1, 0)), index=df.index)
        signal &= is_wdo_market_hours(df.index)
        return signal

    elif fam == 'bb_reversion':
        std_mult = p.get('std_mult', 2.0)
        upper_band = df['bb_mid'] + (df['rolling_std_20'] * std_mult)
        lower_band = df['bb_mid'] - (df['rolling_std_20'] * std_mult)
        
        if direction in [1, 0]:
            buy_signal = (df['close'] < lower_band) & (df['close'].shift(1) >= lower_band.shift(1))
        if direction in [-1, 0]:
            sell_signal = (df['close'] > upper_band) & (df['close'].shift(1) <= upper_band.shift(1))
        
        signal = pd.Series(np.where(buy_signal, 1, np.where(sell_signal, -1, 0)), index=df.index)
        signal &= time_filter
        return signal

    elif fam == 'rsi_reversal':
        buy_level = p.get('buy_level', 30)
        sell_level = p.get('sell_level', 70)
        
        if direction in [1, 0]:
            buy_signal = (df['rsi_14'] < buy_level) & (df['rsi_14'].shift(1) >= buy_level)
        if direction in [-1, 0]:
            sell_signal = (df['rsi_14'] > sell_level) & (df['rsi_14'].shift(1) <= sell_level)
        
        signal = pd.Series(np.where(buy_signal, 1, np.where(sell_signal, -1, 0)), index=df.index)
        signal &= time_filter
        return signal
    else:
        return pd.Series(0, index=df.index)

# ----------------------
# Ensemble generation for live signals
# ----------------------
def generate_ensemble_signal_live(df, hall_of_fame_strategies, symbol):
    if not hall_of_fame_strategies:
        return pd.Series(0, index=df.index), 2.0, 4.0 # Default SL/TP if no strategies

    infos = []
    for ind in hall_of_fame_strategies:
        sig = signal_from_strategy(df, ind)
        # For live, we don't need to simulate PnL or calculate weights based on profit/sharpe.
        # We assume the strategies in HoF are already good and have equal weight for ensemble.
        # Or, if backtest_ia_5min.py saved weights, we could load them.
        # For simplicity, we'll use equal weighting for now.
        infos.append({'signal': sig, 'weight': 1.0})
    
    if not infos:
        return pd.Series(0, index=df.index), 2.0, 4.0

    # Normalize weights (equal for now)
    total_w = sum(i['weight'] for i in infos)
    for i in infos:
        i['norm_w'] = i['weight'] / total_w if total_w > 0 else 1.0 / len(infos)

    # Combine signals
    sig_df = pd.DataFrame({f"s{i}": inf['signal'].astype(int) for i, inf in enumerate(infos)}, index=df.index)
    weights = np.array([inf['norm_w'] for inf in infos])
    weighted = sig_df.values.dot(weights)
    ensemble_signal = pd.Series(np.sign(weighted) * (np.abs(weighted) > 0.5), index=df.index, dtype=int)

    # Load optimized SL/TP from pipeline results
    ensemble_config = load_ensemble_config_from_pipeline_results(symbol)
    best_sl_atr = ensemble_config.get('best_sl_atr', 2.0) if ensemble_config else 2.0
    best_tp_atr = ensemble_config.get('best_tp_atr', 4.0) if ensemble_config else 4.0

    return ensemble_signal, best_sl_atr, best_tp_atr


def salvar_sinal_db(ativo, sinal, preco, confianca):
    """Salva sinal (CSV) e cria lock para impedir novos sinais at√© ordem fechar."""
    try:
        # Se j√° existe lock, ignora
        if sinal_bloqueado():
            logger.info("salvar_sinal_db: lock presente -> ignorando grava√ß√£o")
            return False

        # grava CSV com filelock
        with filelock.FileLock(f"{SINAIS_CSV}.lock"):
            new = f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')},{ativo},{sinal},{preco},{confianca:.3f},OK\n"
            with open(SINAIS_CSV, "a", encoding="utf-8") as f:
                f.write(new)
        logger.info(f"Sinal salvo: {ativo} {sinal} {preco} conf={confianca:.3f}")

        # bloqueia novos sinais
        bloquear_sinal()
        return True
    except PermissionError as pe:
        logger.warning(f"PermissionError salvar_sinal_db: {pe} - tentando fallback no home")
        try:
            fallback = os.path.join(str(Path.home()), "ia_finance_sinais_ao_vivo.csv")
            with filelock.FileLock(f"{fallback}.lock"):
                with open(fallback, "a", encoding="utf-8") as f:
                    f.write(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')},{ativo},{sinal},{preco},{confianca:.3f},OK\n")
            bloquear_sinal()
            logger.info(f"Sinal salvo em fallback {fallback}")
            return True
        except Exception as e:
            logger.error(f"Falha fallback salvar_sinal_db: {e}")
            return False
    except Exception as e:
        logger.error(f"salvar_sinal_db erro: {e}")
        return False

# ----------------------
# NOT√çCIAS
# ----------------------
def analisar_noticias():
    global ultima_verificacao_noticias, cache_noticias
    agora = datetime.now()
    if ultima_verificacao_noticias and (agora - ultima_verificacao_noticias).seconds < 600:
        return cache_noticias
    feeds = [
        'https://www.infomoney.com.br/feed/',
        'https://economia.uol.com.br/rss/',
        'https://valorinveste.globo.com/rss/ultimas.xml'
    ]
    palavras_alto_risco = ['copom','juros','infla√ß√£o','recess√£o','crise','default','selic','fed']
    score_risco = 0.0
    for feed_url in feeds:
        try:
            rss = feedparser.parse(feed_url)
            for entry in rss.entries[:10]:
                titulo = (entry.title + " " + getattr(entry,'summary','')).lower()
                if any(p in titulo for p in palavras_alto_risco):
                    score_risco += 0.4
        except Exception as e:
            logger.debug(f"analisar_noticias: {e}")
            continue
    cache_noticias = min(1.0, score_risco)
    ultima_verificacao_noticias = agora
    return cache_noticias

# ----------------------
# gerar_sinal_IA (com modelo por ativo)
# ----------------------
def gerar_sinal_IA(simbolo, timeframe, lookback=200): # Removed melhores_params
    global ultimo_sinal
    logger.info(f"Gerando sinal para {simbolo}...")

    # n√£o gerar se lock ativo
    if sinal_bloqueado():
        logger.debug("gerar_sinal_IA: lock ativo, n√£o gera sinal")
        # Return all expected values with defaults
        return None, None, 0.0, 2.0, 4.0, 0.0, None

    # --- 1. Fetch data ---
    try:
        rates = mt5.copy_rates_from_pos(simbolo, timeframe, 0, lookback)
    except Exception as e:
        logger.error(f"gerar_sinal_IA: mt5.copy_rates_from_pos erro: {e}")
        return None, None, 0.0, 2.0, 4.0, 0.0, None
    
    # Initialize SL/TP with defaults, will be updated by ensemble config
    best_sl_atr, best_tp_atr = 2.0, 4.0
    if rates is None or len(rates) < 100: # Need enough data for feature calculation
        return None, None, 0.0, best_sl_atr, best_tp_atr, 0.0, None

    df = pd.DataFrame(rates)
    # converter time unix -> datetime
    if 'time' in df.columns:
        df['datetime'] = pd.to_datetime(df['time'], unit='s')
        df = df.set_index('datetime')
    elif 'datetime' in df.columns:
        df['datetime'] = pd.to_datetime(df['datetime'])
        df = df.set_index('datetime')
    else:
        # fallback
        df['datetime'] = pd.to_datetime(df.index, unit='s', errors='coerce')
        df = df.set_index('datetime')

    # --- FIX: Normalize column names from MT5 ---
    # MT5 returns 'tick_volume', but the backtest logic uses 'tickvol'.
    if 'tick_volume' in df.columns:
        df.rename(columns={'tick_volume': 'tickvol'}, inplace=True)

    df = df[['open','high','low','close','tickvol']].copy()
    df.attrs['asset_name'] = simbolo # Store asset name for feature functions

    # --- 2. Calculate features (exactly as in backtest_ia_5min.py) ---
    df = add_features(df)
    if df is None or len(df) < 50: # Need enough data after dropping NaNs
        return None, None, 0.0, best_sl_atr, best_tp_atr, 0.0, None

    # --- 3. Load Hall of Fame strategies and generate ensemble signal ---
    hall_of_fame_strategies = load_hall_of_fame_strategies(simbolo)
    ensemble_signal, _, _ = generate_ensemble_signal_live(df, hall_of_fame_strategies, simbolo)
    
    # --- 4. Prepare ML dataset (last row) ---
    ml_features = carregar_features_IA(simbolo)
    if not ml_features:
        logger.error(f"Features para ML n√£o carregadas para {simbolo}. Usando fallback.")
        # Fallback to simple ensemble if ML features not found
        final_signal_value = ensemble_signal.iloc[-1] if not ensemble_signal.empty else 0
        confianca = 0.6 if final_signal_value != 0 else 0.0
        return ("COMPRA" if final_signal_value == 1 else "VENDA" if final_signal_value == -1 else None), float(df['close'].iloc[-1]), confianca, best_sl_atr, best_tp_atr, df['atr_14'].iloc[-1], df

    # Ensure ensemble signal is available as a feature
    df['ens_sig'] = ensemble_signal.astype(int)

    # Create X for prediction using the exact features the model was trained on
    X_pred = df[ml_features].iloc[-1].to_frame().T # Last row, as a DataFrame

    # --- 5. Load ML model and ensemble config ---
    modelo = carregar_modelo_IA(simbolo)
    ensemble_config = load_ensemble_config_from_pipeline_results(simbolo) # This also updates best_sl_atr, best_tp_atr
    optimized_ml_threshold = ensemble_config.get('optimized_ml_threshold', 0.55) if ensemble_config else 0.55

    # --- 6. ML Prediction and Filtering ---
    previsao = None
    confianca = 0.0
    if modelo is not None:
        try:
            # Get probability of positive class (label=1)
            prob_up = modelo.predict_proba(X_pred)[0, 1]
            
            # The ML model predicts the probability of the price going UP (label=1)
            # We use this to filter the ensemble signal
            ensemble_sig_value = ensemble_signal.iloc[-1]

            if ensemble_sig_value == 1: # Ensemble wants to BUY
                if prob_up >= optimized_ml_threshold:
                    previsao = 1 # ML confirms BUY
                    confianca = prob_up
                else:
                    previsao = 0 # ML rejects BUY
                    confianca = 1 - prob_up # Confidence in rejection
            elif ensemble_sig_value == -1: # Ensemble wants to SELL
                if prob_up <= (1 - optimized_ml_threshold): # ML predicts price will go DOWN
                    previsao = -1 # ML confirms SELL
                    confianca = 1 - prob_up
                else:
                    previsao = 0 # ML rejects SELL
                    confianca = prob_up # Confidence in rejection
            else:
                previsao = 0  # inconclusivo
                confianca = 0.0
            
            logger.debug(f"Ensemble: {ensemble_sig_value}, ML Prob Up: {prob_up:.3f}, ML Threshold: {optimized_ml_threshold:.2f} -> Final Pred: {previsao}, Conf: {confianca:.3f}")

        except Exception as e:
            logger.error(f"Erro predict modelo {simbolo}: {e}")
            previsao = 0
    else:
        logger.warning(f"Modelo ML n√£o carregado para {simbolo}. Usando apenas sinal do ensemble.")
        previsao = ensemble_signal.iloc[-1] if not ensemble_signal.empty else 0 # Use ensemble signal as prediction
        confianca = 0.6 if previsao != 0 else 0.0 # Assign a default confidence if no ML model is used

    # transformar previsao para sinal textual
    sinal = None
    if previsao == 1:
        sinal = "COMPRA"
    elif previsao == -1:
        sinal = "VENDA"
    else:
        sinal = None

    # bloqueios/evitar repeti√ß√£o
    if (ultimo_sinal == "COMPRA" and sinal == "COMPRA") or (ultimo_sinal == "VENDA" and sinal == "VENDA") or (sinal is None):
        return None, float(df['close'].iloc[-1]), 0.0, best_sl_atr, best_tp_atr, df['atr_14'].iloc[-1], df

    # not√≠cias
    risco_noticias = analisar_noticias()
    if risco_noticias > 0.5:
        logger.warning(f"Bloqueio por not√≠cias ({risco_noticias:.2f})")
        return None, float(df['close'].iloc[-1]), 0.0, best_sl_atr, best_tp_atr, df['atr_14'].iloc[-1], df

    # s√≥ envia se mercado aberto (configurable)
    agora = datetime.now()
    # Assuming market hours are 9:00 to 17:00 for general assets
    mercado_aberto = (agora.hour >= 9 and agora.hour < 17) or (agora.hour == 17 and agora.minute == 0)
    
    ultimo_preco = float(df['close'].iloc[-1])
    if mercado_aberto and sinal is not None and confianca > 0.5: # Only trade if confident
        ok = salvar_sinal_db(simbolo, sinal, ultimo_preco, confianca)
        if ok:
            ultimo_sinal = sinal # Update global last signal
            return sinal, ultimo_preco, confianca, best_sl_atr, best_tp_atr, df['atr_14'].iloc[-1], df

    return None, ultimo_preco, 0.0, best_sl_atr, best_tp_atr, df['atr_14'].iloc[-1], df

# ----------------------
# verificar ordens e liberar lock se nenhuma posi√ß√£o
# ----------------------
def verificar_ordens_fechadas():
    try:
        pos = mt5.positions_get()
        if pos is None or len(pos) == 0:
            # se n√£o h√° posi√ß√µes abertas do rob√¥, libera lock
            if sinal_bloqueado():
                liberar_sinal()
            return True
        # ainda tem posi√ß√µes -> manter lock
        return False
    except Exception as e:
        logger.debug(f"verificar_ordens_fechadas erro: {e}")
        return False

# --- Main loop for testing (if you want to run sinais.py directly for testing) ---
if __name__ == "__main__":
    if initialize_mt5():
        # Exemplo de uso para um s√≠mbolo
        # --- FIX: Use a specific, mappable symbol for testing, just like the dashboard would ---
        sinal, preco, confianca, sl_atr, tp_atr, atr_val, df_data = gerar_sinal_IA("WINZ25", mt5.TIMEFRAME_M5, lookback=500)
        logger.info(f"Sinal final para WIN$: {sinal} @ {preco} (Conf: {confianca:.3f}) SL_ATR: {sl_atr}, TP_ATR: {tp_atr}, ATR: {atr_val:.2f}")
        mt5.shutdown()
